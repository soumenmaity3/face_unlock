{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa27e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with 'tuple' literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Set the name for the dataset directory\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set the name for the dataset directory\n",
    "dataset_name = \"my_face\"\n",
    "dataset_path = f\"dataset/{dataset_name}\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "# Load Haar cascade for face detection\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def capture_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    # Crop just the face region\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "total_images = 100\n",
    "\n",
    "print(\"Please look at the camera...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if capture_face(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(capture_face(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        file_name_path = f\"{dataset_path}/{count}.jpg\"\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.imshow(\"Face Dataset\", face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == total_images: # Press Enter to exit early\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Collected {count} face samples. Dataset stored at {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1a51d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face images...\n",
      "Loaded 100 face images.\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Create and train the LBPH face recognizer\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m face_recognizer = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mface\u001b[49m.LBPHFaceRecognizer_create()\n\u001b[32m     47\u001b[39m face_recognizer.train(faces_np, labels_np)\n\u001b[32m     48\u001b[39m face_recognizer.save(\u001b[33m\"\u001b[39m\u001b[33mtrained_model.yml\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to face dataset\n",
    "dataset_path = \"dataset/my_face\"\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Error: Dataset path '{dataset_path}' does not exist!\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data for training\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "# Label for your face\n",
    "label = 1\n",
    "\n",
    "print(\"Loading face images...\")\n",
    "image_count = 0\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(dataset_path, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is not None:\n",
    "            faces.append(img)\n",
    "            labels.append(label)\n",
    "            image_count += 1\n",
    "        else:\n",
    "            print(f\"Warning: Could not read {filename}\")\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print(\"Error: No face images found in dataset!\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {image_count} face images.\")\n",
    "\n",
    "faces_np = np.array(faces)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Create and train the LBPH face recognizer\n",
    "print(\"Training model...\")\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(faces_np, labels_np)\n",
    "face_recognizer.save(\"trained_model.yml\")\n",
    "\n",
    "print(\"âœ“ Training complete. Model saved as trained_model.yml.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3be7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for your face...\n",
      "âœ“ Face verified! Access granted.\n",
      "ðŸ”“ System unlocked successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read(\"trained_model.yml\")\n",
    "\n",
    "# Load face cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Looking for your face...\")\n",
    "\n",
    "# Recognition parameters\n",
    "confidence_threshold = 70  # Lower = stricter, Higher = more lenient\n",
    "recognition_count = 0\n",
    "required_recognitions = 5  # Need 5 consecutive recognitions to unlock\n",
    "\n",
    "unlocked = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if frame was read successfully\n",
    "    if not ret or frame is None:\n",
    "        print(\"Error: Could not read frame from camera\")\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (200, 200))\n",
    "        \n",
    "        # Predict\n",
    "        label, confidence = face_recognizer.predict(face_roi)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        if confidence < confidence_threshold and label == 1:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Recognized! ({int(confidence)})\", (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            recognition_count += 1\n",
    "            \n",
    "            if recognition_count >= required_recognitions:\n",
    "                print(\"âœ“ Face verified! Access granted.\")\n",
    "                unlocked = True\n",
    "                break  # Break from for loop\n",
    "        else:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"Unknown ({int(confidence)})\", (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            recognition_count = 0  # Reset counter\n",
    "    \n",
    "    # Break from while loop if unlocked\n",
    "    if unlocked:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    \n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if unlocked:\n",
    "    print(\"ðŸ”“ System unlocked successfully!\")\n",
    "    # HERE: Add your unlock command for your OS\n",
    "else:\n",
    "    print(\"Recognition stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e9203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face unlock running. Looking for your face...\n",
      "Confidence: 46.63398281478578\n",
      "Access Granted: Laptop Unlocked!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# Load the trained model\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read(\"trained_model.yml\")  # path to your model\n",
    "\n",
    "# Load Haar cascade for face detection\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def detect_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        return gray[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "unlock_threshold = 55  # Adjust based on training and testing\n",
    "\n",
    "print(\"Face unlock running. Looking for your face...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    face = detect_face(frame)\n",
    "    if face is not None:\n",
    "        face = cv2.resize(face, (200, 200))\n",
    "        label, confidence = face_recognizer.predict(face)\n",
    "        print(f\"Confidence: {confidence}\")\n",
    "\n",
    "        if confidence < unlock_threshold:\n",
    "            print(\"Access Granted: Laptop Unlocked!\")\n",
    "            # You can implement your unlock logic here\n",
    "            # For example, simulate Ctrl+Alt+Del or show a notification\n",
    "            break\n",
    "        else:\n",
    "            print(\"Access Denied: Locking laptop\")\n",
    "            # Lock screen for Windows (this command)\n",
    "            pyautogui.hotkey('win', 'l')\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        print(\"No face detected...\")\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) == 13:  # Press Enter to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170f419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
